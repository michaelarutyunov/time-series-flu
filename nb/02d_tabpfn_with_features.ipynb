{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02d - TabPFN-TS with Calendar Features\n",
    "\n",
    "Demonstrates how adding simple calendar features transforms TabPFN-TS performance.\n",
    "\n",
    "**Hypothesis:** TabPFN-TS underperforms on univariate data because it's designed for multivariate tabular forecasting. Adding calendar features should unlock its true potential.\n",
    "\n",
    "**Enhancement:**\n",
    "- **Day of week** (captures weekly seasonality)\n",
    "- **Day of year** (captures annual seasonality)\n",
    "- **Month** (categorical time signal)\n",
    "- **Is weekend** (binary indicator)\n",
    "- **Fourier terms** (sin/cos pairs for 7-day and 365-day cycles)\n",
    "\n",
    "**Comparison:**\n",
    "- Baseline: TabPFN-TS (univariate only, from nb/02_roll_loop.ipynb)\n",
    "- Enhanced: TabPFN-TS + calendar features (this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model imports\n",
    "from autogluon.timeseries import TimeSeriesDataFrame\n",
    "from tabpfn_time_series import TabPFNTimeSeriesPredictor, TabPFNMode, FeatureTransformer\n",
    "from tabpfn_time_series.features import RunningIndexFeature, CalendarFeature, AutoSeasonalFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / 'data'\n",
    "results_dir = project_root / 'results' / 'forecasts'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 1078 observations\n",
      "Date range: 2022-07-04 00:00:00 to 2025-06-15 00:00:00\n",
      "Frequency: <Day>\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned time series\n",
    "ts = pd.read_pickle(data_dir / 'flu_daily_clean.pkl')\n",
    "print(f\"Loaded data: {ts.shape[0]} observations\")\n",
    "print(f\"Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "print(f\"Frequency: {ts.index.freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Rolling Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast horizons: [7, 28]\n",
      "Number of forecast origins: 24 (bi-weekly)\n",
      "Minimum training days: 730\n",
      "Total forecasts: 48\n"
     ]
    }
   ],
   "source": [
    "# Same configuration as nb/02_roll_loop.ipynb for fair comparison\n",
    "HORIZONS = [7, 28]\n",
    "ORIGINS = pd.date_range('2024-07-08', '2025-05-26', freq='2W-MON')\n",
    "MIN_TRAIN = 730  # 2 years minimum training data\n",
    "\n",
    "print(f\"Forecast horizons: {HORIZONS}\")\n",
    "print(f\"Number of forecast origins: {len(ORIGINS)} (bi-weekly)\")\n",
    "print(f\"Minimum training days: {MIN_TRAIN}\")\n",
    "print(f\"Total forecasts: {len(ORIGINS) * len(HORIZONS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize TabPFN Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TabPFN client initialized\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import tabpfn_client\n",
    "\n",
    "# Load API key from .env\n",
    "env_file = project_root / \".env\"\n",
    "if env_file.exists():\n",
    "    load_dotenv(env_file)\n",
    "    api_key = os.getenv(\"PRIORLABS_API_KEY\")\n",
    "    if api_key:\n",
    "        tabpfn_client.set_access_token(api_key)\n",
    "        print(\"✅ TabPFN client initialized\")\n",
    "    else:\n",
    "        print(\"⚠️  PRIORLABS_API_KEY not found in .env\")\n",
    "else:\n",
    "    print(\"⚠️  .env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Official TabPFN Feature Engineering\n",
    "\n",
    "TabPFN provides specialized features optimized for time series forecasting:\n",
    "- **RunningIndexFeature**: Time index for trend extrapolation\n",
    "- **CalendarFeature**: Sine/cosine transformations for cyclical calendar patterns\n",
    "- **AutoSeasonalFeature**: DFT-based adaptive seasonality detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FeatureTransformer initialized with:\n",
      "   - RunningIndexFeature\n",
      "   - CalendarFeature\n",
      "   - AutoSeasonalFeature\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature transformer with official TabPFN features\n",
    "selected_features = [\n",
    "    RunningIndexFeature(),      # Adds time index (0, 1, 2, ...) for trend extrapolation\n",
    "    CalendarFeature(),           # Sine/cosine encoding of calendar components\n",
    "    AutoSeasonalFeature(),       # DFT-based seasonality detection from training data\n",
    "]\n",
    "\n",
    "feature_transformer = FeatureTransformer(selected_features)\n",
    "\n",
    "print(\"✅ FeatureTransformer initialized with:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"   - {feat.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: ['target']\n",
      "\n",
      "Columns after FeatureTransformer: ['target', 'running_index', 'year', 'second_of_minute_sin', 'second_of_minute_cos', 'minute_of_hour_sin', 'minute_of_hour_cos', 'hour_of_day_sin', 'hour_of_day_cos', 'day_of_week_sin', 'day_of_week_cos', 'day_of_month_sin', 'day_of_month_cos', 'day_of_year_sin', 'day_of_year_cos', 'week_of_year_sin', 'week_of_year_cos', 'month_of_year_sin', 'month_of_year_cos', 'sin_#0', 'cos_#0', 'sin_#1', 'cos_#1', 'sin_#2', 'cos_#2', 'sin_#3', 'cos_#3', 'sin_#4', 'cos_#4']\n",
      "Total features added: 28\n",
      "\n",
      "Sample with features:\n",
      "                      target  running_index  year  second_of_minute_sin  \\\n",
      "item_id timestamp                                                         \n",
      "test    2024-01-01  0.374540              0  2024                   0.0   \n",
      "        2024-01-02  0.950714              1  2024                   0.0   \n",
      "        2024-01-03  0.731994              2  2024                   0.0   \n",
      "        2024-01-04  0.598658              3  2024                   0.0   \n",
      "        2024-01-05  0.156019              4  2024                   0.0   \n",
      "\n",
      "                    second_of_minute_cos  minute_of_hour_sin  \\\n",
      "item_id timestamp                                              \n",
      "test    2024-01-01                   1.0                 0.0   \n",
      "        2024-01-02                   1.0                 0.0   \n",
      "        2024-01-03                   1.0                 0.0   \n",
      "        2024-01-04                   1.0                 0.0   \n",
      "        2024-01-05                   1.0                 0.0   \n",
      "\n",
      "                    minute_of_hour_cos  hour_of_day_sin  hour_of_day_cos  \\\n",
      "item_id timestamp                                                          \n",
      "test    2024-01-01                 1.0              0.0              1.0   \n",
      "        2024-01-02                 1.0              0.0              1.0   \n",
      "        2024-01-03                 1.0              0.0              1.0   \n",
      "        2024-01-04                 1.0              0.0              1.0   \n",
      "        2024-01-05                 1.0              0.0              1.0   \n",
      "\n",
      "                    day_of_week_sin  ...    sin_#0    cos_#0  sin_#1  cos_#1  \\\n",
      "item_id timestamp                    ...                                       \n",
      "test    2024-01-01     0.000000e+00  ...  0.000000  1.000000     0.0     0.0   \n",
      "        2024-01-02     8.660254e-01  ...  0.781831  0.623490     0.0     0.0   \n",
      "        2024-01-03     8.660254e-01  ...  0.974928 -0.222521     0.0     0.0   \n",
      "        2024-01-04     1.224647e-16  ...  0.433884 -0.900969     0.0     0.0   \n",
      "        2024-01-05    -8.660254e-01  ... -0.433884 -0.900969     0.0     0.0   \n",
      "\n",
      "                    sin_#2  cos_#2  sin_#3  cos_#3  sin_#4  cos_#4  \n",
      "item_id timestamp                                                   \n",
      "test    2024-01-01     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "        2024-01-02     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "        2024-01-03     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "        2024-01-04     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "        2024-01-05     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test on a small sample\n",
    "test_df = pd.DataFrame({\n",
    "    'timestamp': pd.date_range('2024-01-01', periods=10, freq='D'),\n",
    "    'target': np.random.rand(10),\n",
    "    'item_id': 'test'\n",
    "})\n",
    "\n",
    "test_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "    test_df,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Create test data (forecast period)\n",
    "test_forecast_df = pd.DataFrame({\n",
    "    'timestamp': pd.date_range('2024-01-11', periods=5, freq='D'),\n",
    "    'target': np.nan,\n",
    "    'item_id': 'test'\n",
    "})\n",
    "\n",
    "test_forecast_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "    test_forecast_df,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Apply feature transformer\n",
    "train_with_features, test_with_features = feature_transformer.transform(test_tsdf, test_forecast_tsdf)\n",
    "\n",
    "print(\"Original columns:\", list(test_tsdf.columns))\n",
    "print(f\"\\nColumns after FeatureTransformer: {list(train_with_features.columns)}\")\n",
    "print(f\"Total features added: {len(train_with_features.columns) - 1}\")  # -1 for 'target'\n",
    "\n",
    "print(\"\\nSample with features:\")\n",
    "print(train_with_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TabPFN-TS with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_tabpfn_enhanced(train_series, horizon, feature_transformer, item_id='flu_positivity'):\n",
    "    \"\"\"\n",
    "    Forecast with TabPFN-TS using official FeatureTransformer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_series : pd.Series\n",
    "        Training data (datetime-indexed)\n",
    "    horizon : int\n",
    "        Number of steps ahead to forecast\n",
    "    feature_transformer : FeatureTransformer\n",
    "        Initialized FeatureTransformer with selected features\n",
    "    item_id : str\n",
    "        Identifier for the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {'q0.1': float, 'q0.5': float, 'q0.9': float}\n",
    "        Forecast quantiles\n",
    "    \"\"\"\n",
    "    # Prepare training data as TimeSeriesDataFrame\n",
    "    df_prep = train_series.reset_index()\n",
    "    df_prep.columns = ['timestamp', 'target']\n",
    "    df_prep['item_id'] = item_id\n",
    "\n",
    "    train_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        df_prep,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "\n",
    "    # Create test dates (forecast horizon)\n",
    "    forecast_start = train_series.index[-1] + pd.Timedelta(days=1)\n",
    "    test_dates = pd.date_range(forecast_start, periods=horizon, freq='D')\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        'timestamp': test_dates,\n",
    "        'item_id': item_id,\n",
    "        'target': np.nan\n",
    "    })\n",
    "\n",
    "    test_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        test_df,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "\n",
    "    # Apply feature transformer\n",
    "    train_tsdf, test_tsdf = feature_transformer.transform(train_tsdf, test_tsdf)\n",
    "\n",
    "    # Initialize predictor and forecast\n",
    "    predictor = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n",
    "    pred = predictor.predict(train_tsdf, test_tsdf)\n",
    "\n",
    "    # Extract final horizon prediction\n",
    "    pred_slice = pred.loc[item_id]\n",
    "\n",
    "    return {\n",
    "        'q0.1': float(pred_slice[0.1].iloc[-1]),\n",
    "        'q0.5': float(pred_slice[0.5].iloc[-1]),\n",
    "        'q0.9': float(pred_slice[0.9].iloc[-1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test TabPFN-TS with Official Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 698 days\n",
      "Train range: 2022-07-04 00:00:00 to 2024-05-31 00:00:00\n",
      "\n",
      "Testing TabPFN-TS with official FeatureTransformer (may take a few seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 123.76it/s]\n",
      "Processing: 100%|██████████| [00:03<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast for 2024-06-07 00:00:00:\n",
      "  q0.1: 0.50%\n",
      "  q0.5: 0.74%\n",
      "  q0.9: 0.97%\n",
      "\n",
      "Actual: 0.90%\n",
      "Within 80% interval: True\n"
     ]
    }
   ],
   "source": [
    "# Test on a single rolling window\n",
    "test_origin = pd.Timestamp('2024-06-01')\n",
    "test_horizon = 7\n",
    "\n",
    "# Get training data\n",
    "train = ts[ts.index < test_origin]\n",
    "print(f\"Train size: {len(train)} days\")\n",
    "print(f\"Train range: {train.index.min()} to {train.index.max()}\")\n",
    "\n",
    "# Generate forecast\n",
    "print(\"\\nTesting TabPFN-TS with official FeatureTransformer (may take a few seconds)...\")\n",
    "pred = forecast_tabpfn_enhanced(train, test_horizon, feature_transformer)\n",
    "\n",
    "target_date = test_origin + pd.Timedelta(days=test_horizon - 1)\n",
    "print(f\"\\nForecast for {target_date}:\")\n",
    "print(f\"  q0.1: {pred['q0.1']:.2f}%\")\n",
    "print(f\"  q0.5: {pred['q0.5']:.2f}%\")\n",
    "print(f\"  q0.9: {pred['q0.9']:.2f}%\")\n",
    "\n",
    "# Compare to actual\n",
    "if target_date in ts.index:\n",
    "    actual = ts.loc[target_date]\n",
    "    print(f\"\\nActual: {actual:.2f}%\")\n",
    "    print(f\"Within 80% interval: {pred['q0.1'] <= actual <= pred['q0.9']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rolling Forecast Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_forecasts_enhanced(ts, origins, horizons, min_train, feature_transformer):\n",
    "    \"\"\"\n",
    "    Run rolling forecasts for TabPFN-TS with official FeatureTransformer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : pd.Series\n",
    "        Full time series\n",
    "    origins : pd.DatetimeIndex\n",
    "        Forecast origin dates\n",
    "    horizons : list of int\n",
    "        Forecast horizons\n",
    "    min_train : int\n",
    "        Minimum training window size\n",
    "    feature_transformer : FeatureTransformer\n",
    "        Initialized FeatureTransformer with selected features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Forecast results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Progress bar\n",
    "    total_iter = len(origins) * len(horizons)\n",
    "    pbar = tqdm(total=total_iter, desc=\"TabPFN-TS Enhanced rolling forecasts\")\n",
    "\n",
    "    for origin in origins:\n",
    "        # Get training data (all data before origin)\n",
    "        train = ts[ts.index < origin]\n",
    "\n",
    "        # Skip if insufficient training data\n",
    "        if len(train) < min_train:\n",
    "            continue\n",
    "\n",
    "        for horizon in horizons:\n",
    "            # Target forecast date\n",
    "            target_date = origin + pd.Timedelta(days=horizon - 1)\n",
    "\n",
    "            # Skip if target date is beyond available data\n",
    "            if target_date not in ts.index:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Get actual value\n",
    "            actual = ts.loc[target_date]\n",
    "\n",
    "            # TabPFN-TS Enhanced\n",
    "            try:\n",
    "                pred = forecast_tabpfn_enhanced(train, horizon, feature_transformer)\n",
    "                results.append({\n",
    "                    'date': target_date,\n",
    "                    'origin': origin,\n",
    "                    'horizon': horizon,\n",
    "                    'model': 'TabPFN_Enhanced',\n",
    "                    'q0.1': pred['q0.1'],\n",
    "                    'q0.5': pred['q0.5'],\n",
    "                    'q0.9': pred['q0.9'],\n",
    "                    'actual': actual\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️  Failed forecast for origin={origin}, horizon={horizon}: {e}\")\n",
    "                pass  # Skip failed forecasts\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Rolling Forecasts\n",
    "\n",
    "**Warning:** This will make API calls and take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TabPFN-TS Enhanced rolling forecast generation...\n",
      "Total iterations: 48\n",
      "\n",
      "Using official TabPFN features:\n",
      "  - RunningIndexFeature (trend/extrapolation)\n",
      "  - CalendarFeature (cyclical encoding)\n",
      "  - AutoSeasonalFeature (DFT-based seasonality)\n",
      "\n",
      "This will take approximately 5-8 minutes (API calls)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 782.52it/s]?it/s]\n",
      "Processing: 100%|██████████| [00:03<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1554.02it/s]1,  8.33s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1038.45it/s]6,  7.09s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1402.31it/s]3,  6.98s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1395.78it/s]5,  7.17s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1406.54it/s]4,  7.32s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 865.70it/s]54,  7.00s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1405.13it/s]9,  7.54s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1003.90it/s]6,  7.67s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1190.21it/s]2,  7.74s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 868.75it/s]:01,  7.95s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1931.08it/s]50,  7.85s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1201.81it/s]49,  8.05s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1167.68it/s]55,  8.44s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1255.78it/s]34,  8.07s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 953.90it/s]:37,  8.40s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 970.23it/s]:20,  8.15s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1125.99it/s]30,  8.74s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 857.73it/s]:14,  8.49s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1363.11it/s]29,  9.29s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1264.11it/s]08,  8.86s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1520.78it/s]15,  9.48s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1310.31it/s]56,  9.10s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1281.88it/s]50,  9.22s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1066.17it/s]45,  9.38s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1339.18it/s]39,  9.54s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1177.18it/s]37,  9.87s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1163.47it/s]43, 10.63s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 985.97it/s]:36, 10.81s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1524.65it/s]27, 10.91s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1303.39it/s]13, 10.76s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1615.06it/s]02, 10.72s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 944.45it/s]:53, 10.85s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1324.80it/s]44, 10.97s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1272.54it/s]27, 10.51s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1492.10it/s]18, 10.68s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1349.52it/s]11, 10.94s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1380.16it/s]01, 11.06s/it]\n",
      "Processing: 100%|██████████| [00:04<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]:58, 11.89s/it]\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 568.26it/s]:23,  9.28s/it]\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1241.65it/s]57,  7.20s/it]\n",
      "Processing: 100%|██████████| [00:02<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1246.45it/s]42,  6.12s/it]\n",
      "Processing: 100%|██████████| [00:03<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1116.40it/s]33,  5.60s/it]\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1075.19it/s]24,  4.85s/it]\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 687.70it/s]:16,  4.10s/it]\n",
      "Processing: 100%|██████████| [00:02<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1056.50it/s]12,  4.06s/it]\n",
      "Processing: 100%|██████████| [00:02<00:00]\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1131.15it/s]07,  3.64s/it]\n",
      "Processing: 100%|██████████| [00:02<00:00]\n",
      "TabPFN-TS Enhanced rolling forecasts: 100%|██████████| 48/48 [06:25<00:00,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Rolling forecasts complete! Generated 47 forecasts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting TabPFN-TS Enhanced rolling forecast generation...\")\n",
    "print(f\"Total iterations: {len(ORIGINS) * len(HORIZONS)}\")\n",
    "print(\"\\nUsing official TabPFN features:\")\n",
    "print(\"  - RunningIndexFeature (trend/extrapolation)\")\n",
    "print(\"  - CalendarFeature (cyclical encoding)\")\n",
    "print(\"  - AutoSeasonalFeature (DFT-based seasonality)\")\n",
    "print(\"\\nThis will take approximately 5-8 minutes (API calls)...\\n\")\n",
    "\n",
    "forecast_results = run_rolling_forecasts_enhanced(\n",
    "    ts=ts,\n",
    "    origins=ORIGINS,\n",
    "    horizons=HORIZONS,\n",
    "    min_train=MIN_TRAIN,\n",
    "    feature_transformer=feature_transformer\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Rolling forecasts complete! Generated {len(forecast_results)} forecasts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 47 forecasts → /home/mikhailarutyunov/projects/time-series-flu/results/forecasts/tabpfn_enhanced.parquet\n",
      "\n",
      "Forecast summary by horizon:\n",
      "horizon\n",
      "7     24\n",
      "28    23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save forecasts\n",
    "output_path = results_dir / 'tabpfn_enhanced.parquet'\n",
    "forecast_results.to_parquet(output_path, index=False)\n",
    "print(f\"✅ Saved {len(forecast_results)} forecasts → {output_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nForecast summary by horizon:\")\n",
    "print(forecast_results.groupby('horizon').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Comparison vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK COMPARISON: TabPFN Baseline vs Enhanced\n",
      "============================================================\n",
      "Baseline (univariate):     MAE = 2.779\n",
      "Enhanced (+ features):     MAE = 2.319\n",
      "Improvement:               +16.5%\n",
      "============================================================\n",
      "\n",
      "Prediction Interval Coverage (nominal 80%):\n",
      "  Baseline: 59.6%\n",
      "  Enhanced: 83.0%\n",
      "  Improvement: +23.4 percentage points\n"
     ]
    }
   ],
   "source": [
    "# Load baseline TabPFN results for comparison\n",
    "baseline_path = results_dir / 'tabpfn.parquet'\n",
    "\n",
    "if baseline_path.exists():\n",
    "    baseline = pd.read_parquet(baseline_path)\n",
    "\n",
    "    # Compute quick MAE comparison\n",
    "    baseline_mae = np.mean(np.abs(baseline['actual'] - baseline['q0.5']))\n",
    "    enhanced_mae = np.mean(np.abs(forecast_results['actual'] - forecast_results['q0.5']))\n",
    "\n",
    "    improvement = (baseline_mae - enhanced_mae) / baseline_mae * 100\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"QUICK COMPARISON: TabPFN Baseline vs Enhanced\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Baseline (univariate):     MAE = {baseline_mae:.3f}\")\n",
    "    print(f\"Enhanced (+ features):     MAE = {enhanced_mae:.3f}\")\n",
    "    print(f\"Improvement:               {improvement:+.1f}%\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Coverage comparison\n",
    "    baseline_cov = np.mean((baseline['actual'] >= baseline['q0.1']) &\n",
    "                           (baseline['actual'] <= baseline['q0.9'])) * 100\n",
    "    enhanced_cov = np.mean((forecast_results['actual'] >= forecast_results['q0.1']) &\n",
    "                           (forecast_results['actual'] <= forecast_results['q0.9'])) * 100\n",
    "\n",
    "    print(f\"\\nPrediction Interval Coverage (nominal 80%):\")\n",
    "    print(f\"  Baseline: {baseline_cov:.1f}%\")\n",
    "    print(f\"  Enhanced: {enhanced_cov:.1f}%\")\n",
    "    print(f\"  Improvement: {enhanced_cov - baseline_cov:+.1f} percentage points\")\n",
    "else:\n",
    "    print(\"⚠️  Baseline results not found. Run nb/02_roll_loop.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checkpoint Summary\n",
    "\n",
    "**Outcomes:**\n",
    "- ✅ `results/forecasts/tabpfn_enhanced.parquet` created with 47-48 forecasts\n",
    "- ✅ Used official TabPFN FeatureTransformer with:\n",
    "  - **RunningIndexFeature**: Time index for trend extrapolation (missing in manual approach)\n",
    "  - **CalendarFeature**: Sine/cosine transformations for cyclical patterns\n",
    "  - **AutoSeasonalFeature**: DFT-based adaptive seasonality (adapts to actual data vs hard-coded)\n",
    "- ✅ No errors or missing forecasts\n",
    "\n",
    "**Key Differences from Manual Approach:**\n",
    "1. **RunningIndexFeature** enables trend extrapolation (critical for forecasting!)\n",
    "2. **AutoSeasonalFeature** uses DFT to detect actual seasonality in flu data (not assumed 7/365-day cycles)\n",
    "3. **FeatureTransformer** ensures consistent feature application to train/test sets\n",
    "4. Expected to significantly improve vs manual features (-4.7% baseline)\n",
    "\n",
    "**Hypothesis:**\n",
    "Previous degradation was due to:\n",
    "- Missing trend/index feature (no extrapolation capability)\n",
    "- Wrong seasonality assumptions (hard-coded vs DFT-detected)\n",
    "- Manual features not in TabPFN's expected format\n",
    "\n",
    "Official approach should unlock TabPFN's true potential on this univariate epidemiological task.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Update `nb/03_evaluation.ipynb` to include TabPFN_Enhanced (official features)\n",
    "2. Compare: TabPFN baseline vs TabPFN_Enhanced (manual) vs TabPFN_Enhanced (official)\n",
    "3. Update `nb/04_report.ipynb` to visualize the improvement\n",
    "\n",
    "**For LinkedIn Article:**\n",
    "> \"Official TabPFN features (RunningIndexFeature + CalendarFeature + AutoSeasonalFeature with DFT) improved performance by X%, demonstrating that foundation models need **the right features, not just any features**. The lesson: **feature engineering is alive—it's just more sophisticated now.**\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
