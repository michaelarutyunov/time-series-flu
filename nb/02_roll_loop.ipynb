{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Rolling Forecast Factory\n",
    "\n",
    "Generate rolling window forecasts for all models: TabPFN-TS, Chronos-Tiny, SARIMA+Fourier, and LightGBM.\n",
    "\n",
    "**Core Configuration:**\n",
    "- Horizons: 1, 7, 14, 28 days ahead\n",
    "- Origins: Daily from 2024-01-01 to 2025-06-01\n",
    "- Minimum training window: 730 days (2 years)\n",
    "\n",
    "**Critical:** All train/test splits use date slicing only (never iloc) to prevent leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model imports\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from autogluon.timeseries import TimeSeriesDataFrame\n",
    "from tabpfn_time_series import TabPFNTimeSeriesPredictor, TabPFNMode\n",
    "from chronos import ChronosPipeline, BaseChronosPipeline\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x72dd902a4910>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / 'data'\n",
    "results_dir = project_root / 'results' / 'forecasts'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 1078 observations\n",
      "Date range: 2022-07-04 00:00:00 to 2025-06-15 00:00:00\n",
      "Frequency: <Day>\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned time series\n",
    "ts = pd.read_pickle(data_dir / 'flu_daily_clean.pkl')\n",
    "print(f\"Loaded data: {ts.shape[0]} observations\")\n",
    "print(f\"Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "print(f\"Frequency: {ts.index.freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Rolling Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast horizons: [7, 28]\n",
      "Number of forecast origins: 24 (bi-weekly)\n",
      "Minimum training days: 730\n",
      "Total forecasts per model: 48\n",
      "\n",
      "✅ Optimized for API efficiency: 48 calls per model\n",
      "   (Covers 11 months, 24 time points, 2 horizons)\n"
     ]
    }
   ],
   "source": [
    "# Forecast configuration - OPTIMIZED for API efficiency\n",
    "HORIZONS = [7, 28]  # Short-term (weekly) vs long-term (monthly) forecasts\n",
    "# Bi-weekly origins = 24 forecast points (statistically robust, API-friendly)\n",
    "ORIGINS = pd.date_range('2024-07-08', '2025-05-26', freq='2W-MON')\n",
    "MIN_TRAIN = 730  # 2 years minimum training data\n",
    "\n",
    "print(f\"Forecast horizons: {HORIZONS}\")\n",
    "print(f\"Number of forecast origins: {len(ORIGINS)} (bi-weekly)\")\n",
    "print(f\"Minimum training days: {MIN_TRAIN}\")\n",
    "print(f\"Total forecasts per model: {len(ORIGINS) * len(HORIZONS)}\")\n",
    "print(f\"\\n✅ Optimized for API efficiency: 48 calls per model\")\n",
    "print(f\"   (Covers 11 months, 24 time points, 2 horizons)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize TabPFN Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TabPFN client initialized\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import tabpfn_client\n",
    "\n",
    "# Load API key from .env\n",
    "env_file = project_root / \".env\"\n",
    "if env_file.exists():\n",
    "    load_dotenv(env_file)\n",
    "    api_key = os.getenv(\"PRIORLABS_API_KEY\")\n",
    "    if api_key:\n",
    "        # CRITICAL: Use set_access_token (NOT init with api_key parameter)\n",
    "        tabpfn_client.set_access_token(api_key)\n",
    "        print(\"✅ TabPFN client initialized\")\n",
    "    else:\n",
    "        print(\"⚠️  PRIORLABS_API_KEY not found in .env\")\n",
    "else:\n",
    "    print(\"⚠️  .env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Chronos Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Chronos-Tiny model (this may take 10-15 seconds)...\n",
      "✅ Chronos-Tiny model loaded (CPU)\n"
     ]
    }
   ],
   "source": [
    "# Suppress transformers/huggingface progress bar warnings\n",
    "import os\n",
    "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'\n",
    "\n",
    "# Load Chronos-Tiny model (CPU-only)\n",
    "print(\"Loading Chronos-Tiny model (this may take 10-15 seconds)...\")\n",
    "chronos_pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-tiny\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "print(\"✅ Chronos-Tiny model loaded (CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fourier_terms(dates, period=365, order=2):\n",
    "    \"\"\"\n",
    "    Build Fourier terms for seasonality from date index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dates : pd.DatetimeIndex\n",
    "        Date index to compute Fourier terms for\n",
    "    period : int\n",
    "        Seasonal period (365 for annual cycle)\n",
    "    order : int\n",
    "        Number of sine/cosine pairs (order=2 gives 4 terms)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Fourier terms with columns sin1, cos1, sin2, cos2, ...\n",
    "    \"\"\"\n",
    "    fourier = pd.DataFrame(index=dates)\n",
    "    for k in range(1, order + 1):\n",
    "        fourier[f'sin{k}'] = np.sin(2 * np.pi * k * np.arange(len(dates)) / period)\n",
    "        fourier[f'cos{k}'] = np.cos(2 * np.pi * k * np.arange(len(dates)) / period)\n",
    "    return fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lag_features(series, lags=[1, 2, 3, 7, 14]):\n",
    "    \"\"\"\n",
    "    Build lag features from a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Time series to create lags from\n",
    "    lags : list of int\n",
    "        Lag values to create\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Dataframe with lag columns\n",
    "    \"\"\"\n",
    "    lag_df = pd.DataFrame(index=series.index)\n",
    "    for lag in lags:\n",
    "        lag_df[f'lag_{lag}'] = series.shift(lag)\n",
    "    return lag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model: SARIMA + Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_sarima_fourier(train_series, horizon, order=(1, 0, 1), fourier_order=2, period=365):\n",
    "    \"\"\"\n",
    "    Forecast with SARIMA + Fourier terms for seasonality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_series : pd.Series\n",
    "        Training data (datetime-indexed)\n",
    "    horizon : int\n",
    "        Number of steps ahead to forecast\n",
    "    order : tuple\n",
    "        ARIMA order (p, d, q)\n",
    "    fourier_order : int\n",
    "        Number of Fourier term pairs\n",
    "    period : int\n",
    "        Seasonal period for Fourier terms\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {'q0.1': float, 'q0.5': float, 'q0.9': float}\n",
    "        Forecast quantiles\n",
    "    \"\"\"\n",
    "    # Create Fourier terms for train period\n",
    "    fourier_train = build_fourier_terms(train_series.index, period=period, order=fourier_order)\n",
    "\n",
    "    # Create Fourier terms for forecast period\n",
    "    forecast_start = train_series.index[-1] + pd.Timedelta(days=1)\n",
    "    forecast_dates = pd.date_range(forecast_start, periods=horizon, freq='D')\n",
    "    fourier_test = build_fourier_terms(forecast_dates, period=period, order=fourier_order)\n",
    "\n",
    "    # Fit SARIMA with Fourier exogenous variables\n",
    "    model = sm.tsa.SARIMAX(\n",
    "        train_series,\n",
    "        order=order,\n",
    "        seasonal_order=(0, 0, 0, 0),  # No seasonal ARIMA (use Fourier instead)\n",
    "        trend='c',\n",
    "        exog=fourier_train\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        fit = model.fit(disp=False, maxiter=200)\n",
    "\n",
    "        # Point forecast\n",
    "        forecast = fit.forecast(steps=horizon, exog=fourier_test)\n",
    "        point = forecast.iloc[-1]\n",
    "\n",
    "        # Get forecast uncertainty (use standard error for intervals)\n",
    "        forecast_obj = fit.get_forecast(steps=horizon, exog=fourier_test)\n",
    "        pred_int = forecast_obj.conf_int(alpha=0.2)  # 80% interval\n",
    "\n",
    "        return {\n",
    "            'q0.1': float(pred_int.iloc[-1, 0]),  # lower bound\n",
    "            'q0.5': float(point),  # median (point forecast)\n",
    "            'q0.9': float(pred_int.iloc[-1, 1])   # upper bound\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # If fitting fails, return naive forecast\n",
    "        naive = float(train_series.iloc[-1])\n",
    "        return {'q0.1': naive * 0.8, 'q0.5': naive, 'q0.9': naive * 1.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SARIMA + Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 698 days\n",
      "Train range: 2022-07-04 00:00:00 to 2024-05-31 00:00:00\n",
      "\n",
      "Forecast for 2024-06-07 00:00:00:\n",
      "  q0.1: -0.09%\n",
      "  q0.5: 1.16%\n",
      "  q0.9: 2.41%\n",
      "\n",
      "Actual: 0.90%\n",
      "Within 80% interval: True\n"
     ]
    }
   ],
   "source": [
    "# Test on a single rolling window\n",
    "test_origin = pd.Timestamp('2024-06-01')\n",
    "test_horizon = 7\n",
    "\n",
    "# Get training data (all data up to origin)\n",
    "train = ts[ts.index < test_origin]\n",
    "print(f\"Train size: {len(train)} days\")\n",
    "print(f\"Train range: {train.index.min()} to {train.index.max()}\")\n",
    "\n",
    "# Generate forecast\n",
    "pred = forecast_sarima_fourier(train, test_horizon)\n",
    "print(f\"\\nForecast for {test_origin + pd.Timedelta(days=test_horizon - 1)}:\")\n",
    "print(f\"  q0.1: {pred['q0.1']:.2f}%\")\n",
    "print(f\"  q0.5: {pred['q0.5']:.2f}%\")\n",
    "print(f\"  q0.9: {pred['q0.9']:.2f}%\")\n",
    "\n",
    "# Compare to actual\n",
    "actual_date = test_origin + pd.Timedelta(days=test_horizon - 1)\n",
    "if actual_date in ts.index:\n",
    "    actual = ts.loc[actual_date]\n",
    "    print(f\"\\nActual: {actual:.2f}%\")\n",
    "    print(f\"Within 80% interval: {pred['q0.1'] <= actual <= pred['q0.9']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model: LightGBM with Lags + Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_lightgbm(train_series, horizon, lags=[1, 2, 3, 7, 14], fourier_order=2, period=365):\n",
    "    \"\"\"\n",
    "    Forecast with LightGBM using lag features + Fourier terms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_series : pd.Series\n",
    "        Training data (datetime-indexed)\n",
    "    horizon : int\n",
    "        Number of steps ahead to forecast\n",
    "    lags : list of int\n",
    "        Lag features to create\n",
    "    fourier_order : int\n",
    "        Number of Fourier term pairs\n",
    "    period : int\n",
    "        Seasonal period for Fourier terms\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {'q0.1': float, 'q0.5': float, 'q0.9': float}\n",
    "        Forecast quantiles\n",
    "    \"\"\"\n",
    "    # Build lag features\n",
    "    lag_df = build_lag_features(train_series, lags=lags)\n",
    "\n",
    "    # Build Fourier features\n",
    "    fourier_df = build_fourier_terms(train_series.index, period=period, order=fourier_order)\n",
    "\n",
    "    # Combine features\n",
    "    X_train = pd.concat([lag_df, fourier_df], axis=1).dropna()\n",
    "    y_train = train_series.loc[X_train.index]\n",
    "\n",
    "    # Train LightGBM models for each quantile\n",
    "    quantiles = [0.1, 0.5, 0.9]\n",
    "    predictions = {}\n",
    "\n",
    "    for q in quantiles:\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective='quantile',\n",
    "            alpha=q,\n",
    "            n_estimators=300,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Multi-step forecast (iterative)\n",
    "        current_series = train_series.copy()\n",
    "\n",
    "        for step in range(horizon):\n",
    "            # Build features for next step\n",
    "            lag_feats = build_lag_features(current_series, lags=lags).iloc[-1:]\n",
    "\n",
    "            # Fourier terms for next date\n",
    "            next_date = current_series.index[-1] + pd.Timedelta(days=1)\n",
    "            fourier_feats = build_fourier_terms(pd.DatetimeIndex([next_date]), period=period, order=fourier_order)\n",
    "\n",
    "            # Combine and predict\n",
    "            X_next = pd.concat([lag_feats, fourier_feats], axis=1)\n",
    "            pred = model.predict(X_next)[0]\n",
    "\n",
    "            # Append prediction to series for next iteration\n",
    "            current_series = pd.concat([\n",
    "                current_series,\n",
    "                pd.Series([pred], index=[next_date])\n",
    "            ])\n",
    "\n",
    "        # Store final prediction\n",
    "        predictions[f'q{q}'] = float(pred)\n",
    "\n",
    "    # Enforce quantile monotonicity: q0.1 ≤ q0.5 ≤ q0.9\n",
    "    # This fixes the quantile crossing issue in LightGBM quantile regression\n",
    "    predictions['q0.1'] = min(predictions['q0.1'], predictions['q0.5'])\n",
    "    predictions['q0.9'] = max(predictions['q0.5'], predictions['q0.9'])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM forecast for 2024-06-07 00:00:00:\n",
      "  q0.1: 0.70%\n",
      "  q0.5: 1.02%\n",
      "  q0.9: 1.45%\n",
      "\n",
      "Actual: 0.90%\n",
      "Within 80% interval: True\n"
     ]
    }
   ],
   "source": [
    "# Test LightGBM on same window\n",
    "pred_lgb = forecast_lightgbm(train, test_horizon)\n",
    "print(f\"LightGBM forecast for {actual_date}:\")\n",
    "print(f\"  q0.1: {pred_lgb['q0.1']:.2f}%\")\n",
    "print(f\"  q0.5: {pred_lgb['q0.5']:.2f}%\")\n",
    "print(f\"  q0.9: {pred_lgb['q0.9']:.2f}%\")\n",
    "print(f\"\\nActual: {actual:.2f}%\")\n",
    "print(f\"Within 80% interval: {pred_lgb['q0.1'] <= actual <= pred_lgb['q0.9']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model: TabPFN-TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_tabpfn(train_series, horizon, item_id='flu_positivity'):\n",
    "    \"\"\"\n",
    "    Forecast with TabPFN-TS (zero-shot foundation model).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_series : pd.Series\n",
    "        Training data (datetime-indexed)\n",
    "    horizon : int\n",
    "        Number of steps ahead to forecast\n",
    "    item_id : str\n",
    "        Identifier for the time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {'q0.1': float, 'q0.5': float, 'q0.9': float}\n",
    "        Forecast quantiles\n",
    "    \"\"\"\n",
    "    # Prepare training data as TimeSeriesDataFrame\n",
    "    df_prep = train_series.reset_index()\n",
    "    df_prep.columns = ['timestamp', 'target']\n",
    "    df_prep['item_id'] = item_id\n",
    "\n",
    "    # Add calendar features\n",
    "    df_prep['day_of_year'] = df_prep['timestamp'].dt.dayofyear\n",
    "    df_prep['month'] = df_prep['timestamp'].dt.month\n",
    "\n",
    "    train_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        df_prep[['item_id', 'timestamp', 'target', 'day_of_year', 'month']],\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "\n",
    "    # Create test dates\n",
    "    forecast_start = train_series.index[-1] + pd.Timedelta(days=1)\n",
    "    test_dates = pd.date_range(forecast_start, periods=horizon, freq='D')\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        'timestamp': test_dates,\n",
    "        'item_id': item_id,\n",
    "        'target': np.nan,\n",
    "        'day_of_year': test_dates.dayofyear,\n",
    "        'month': test_dates.month\n",
    "    })\n",
    "\n",
    "    test_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        test_df,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "\n",
    "    # Initialize predictor and forecast\n",
    "    predictor = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n",
    "    pred = predictor.predict(train_tsdf, test_tsdf)\n",
    "\n",
    "    # Extract final horizon prediction\n",
    "    pred_slice = pred.loc[item_id]\n",
    "\n",
    "    return {\n",
    "        'q0.1': float(pred_slice[0.1].iloc[-1]),\n",
    "        'q0.5': float(pred_slice[0.5].iloc[-1]),\n",
    "        'q0.9': float(pred_slice[0.9].iloc[-1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test TabPFN-TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TabPFN-TS (may take a few seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 696.84it/s]\n",
      "Processing: 100%|██████████| [00:01<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TabPFN-TS forecast for 2024-06-07 00:00:00:\n",
      "  q0.1: 0.40%\n",
      "  q0.5: 0.51%\n",
      "  q0.9: 0.60%\n",
      "\n",
      "Actual: 0.90%\n",
      "Within 80% interval: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test TabPFN-TS on same window (warning: this makes API calls)\n",
    "print(\"Testing TabPFN-TS (may take a few seconds)...\")\n",
    "pred_tabpfn = forecast_tabpfn(train, test_horizon)\n",
    "print(f\"\\nTabPFN-TS forecast for {actual_date}:\")\n",
    "print(f\"  q0.1: {pred_tabpfn['q0.1']:.2f}%\")\n",
    "print(f\"  q0.5: {pred_tabpfn['q0.5']:.2f}%\")\n",
    "print(f\"  q0.9: {pred_tabpfn['q0.9']:.2f}%\")\n",
    "print(f\"\\nActual: {actual:.2f}%\")\n",
    "print(f\"Within 80% interval: {pred_tabpfn['q0.1'] <= actual <= pred_tabpfn['q0.9']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model: Chronos-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_chronos(train_series, horizon, pipeline, num_samples=100):\n",
    "    \"\"\"\n",
    "    Forecast with Chronos-Tiny (zero-shot foundation model).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_series : pd.Series\n",
    "        Training data (datetime-indexed)\n",
    "    horizon : int\n",
    "        Number of steps ahead to forecast\n",
    "    pipeline : ChronosPipeline\n",
    "        Pre-loaded Chronos model pipeline\n",
    "    num_samples : int\n",
    "        Number of forecast samples for quantile estimation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {'q0.1': float, 'q0.5': float, 'q0.9': float}\n",
    "        Forecast quantiles\n",
    "    \"\"\"\n",
    "    # Convert to tensor\n",
    "    context = torch.tensor(train_series.values, dtype=torch.float32)\n",
    "\n",
    "    # Generate forecast samples\n",
    "    forecast_samples = pipeline.predict(\n",
    "        context=context.unsqueeze(0),  # Add batch dimension\n",
    "        prediction_length=horizon,\n",
    "        num_samples=num_samples\n",
    "    )\n",
    "\n",
    "    # Extract final horizon predictions and compute quantiles\n",
    "    final_preds = forecast_samples[0, :, -1].numpy()  # [num_samples]\n",
    "\n",
    "    return {\n",
    "        'q0.1': float(np.quantile(final_preds, 0.1)),\n",
    "        'q0.5': float(np.quantile(final_preds, 0.5)),\n",
    "        'q0.9': float(np.quantile(final_preds, 0.9))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Chronos-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Chronos-Tiny...\n",
      "\n",
      "Chronos-Tiny forecast for 2024-06-07 00:00:00:\n",
      "  q0.1: 0.29%\n",
      "  q0.5: 0.69%\n",
      "  q0.9: 1.19%\n",
      "\n",
      "Actual: 0.90%\n",
      "Within 80% interval: True\n"
     ]
    }
   ],
   "source": [
    "# Test Chronos-Tiny on same window\n",
    "print(\"Testing Chronos-Tiny...\")\n",
    "pred_chronos = forecast_chronos(train, test_horizon, chronos_pipeline)\n",
    "print(f\"\\nChronos-Tiny forecast for {actual_date}:\")\n",
    "print(f\"  q0.1: {pred_chronos['q0.1']:.2f}%\")\n",
    "print(f\"  q0.5: {pred_chronos['q0.5']:.2f}%\")\n",
    "print(f\"  q0.9: {pred_chronos['q0.9']:.2f}%\")\n",
    "print(f\"\\nActual: {actual:.2f}%\")\n",
    "print(f\"Within 80% interval: {pred_chronos['q0.1'] <= actual <= pred_chronos['q0.9']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rolling Forecast Loop\n",
    "\n",
    "**Critical:** Execute all models across all origins × horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_forecasts(ts, origins, horizons, min_train):\n",
    "    \"\"\"\n",
    "    Run rolling forecasts for all models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : pd.Series\n",
    "        Full time series\n",
    "    origins : pd.DatetimeIndex\n",
    "        Forecast origin dates\n",
    "    horizons : list of int\n",
    "        Forecast horizons\n",
    "    min_train : int\n",
    "        Minimum training window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {model_name: pd.DataFrame}\n",
    "        Forecast results by model\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'sarima_fourier': [],\n",
    "        'lightgbm': [],\n",
    "        'tabpfn': [],\n",
    "        'chronos': []\n",
    "    }\n",
    "\n",
    "    # Progress bar\n",
    "    total_iter = len(origins) * len(horizons)\n",
    "    pbar = tqdm(total=total_iter, desc=\"Rolling forecasts\")\n",
    "\n",
    "    for origin in origins:\n",
    "        # Get training data (all data before origin)\n",
    "        train = ts[ts.index < origin]\n",
    "\n",
    "        # Skip if insufficient training data\n",
    "        if len(train) < min_train:\n",
    "            continue\n",
    "\n",
    "        for horizon in horizons:\n",
    "            # Target forecast date\n",
    "            target_date = origin + pd.Timedelta(days=horizon - 1)\n",
    "\n",
    "            # Skip if target date is beyond available data\n",
    "            if target_date not in ts.index:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Get actual value\n",
    "            actual = ts.loc[target_date]\n",
    "\n",
    "            # SARIMA + Fourier\n",
    "            try:\n",
    "                pred_sarima = forecast_sarima_fourier(train, horizon)\n",
    "                results['sarima_fourier'].append({\n",
    "                    'date': target_date,\n",
    "                    'origin': origin,\n",
    "                    'horizon': horizon,\n",
    "                    'model': 'SARIMA_Fourier',\n",
    "                    'q0.1': pred_sarima['q0.1'],\n",
    "                    'q0.5': pred_sarima['q0.5'],\n",
    "                    'q0.9': pred_sarima['q0.9'],\n",
    "                    'actual': actual\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass  # Skip failed forecasts\n",
    "\n",
    "            # LightGBM\n",
    "            try:\n",
    "                pred_lgb = forecast_lightgbm(train, horizon)\n",
    "                results['lightgbm'].append({\n",
    "                    'date': target_date,\n",
    "                    'origin': origin,\n",
    "                    'horizon': horizon,\n",
    "                    'model': 'LightGBM',\n",
    "                    'q0.1': pred_lgb['q0.1'],\n",
    "                    'q0.5': pred_lgb['q0.5'],\n",
    "                    'q0.9': pred_lgb['q0.9'],\n",
    "                    'actual': actual\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            # TabPFN-TS\n",
    "            try:\n",
    "                pred_tabpfn = forecast_tabpfn(train, horizon)\n",
    "                results['tabpfn'].append({\n",
    "                    'date': target_date,\n",
    "                    'origin': origin,\n",
    "                    'horizon': horizon,\n",
    "                    'model': 'TabPFN_TS',\n",
    "                    'q0.1': pred_tabpfn['q0.1'],\n",
    "                    'q0.5': pred_tabpfn['q0.5'],\n",
    "                    'q0.9': pred_tabpfn['q0.9'],\n",
    "                    'actual': actual\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            # Chronos-Tiny\n",
    "            try:\n",
    "                pred_chronos = forecast_chronos(train, horizon, chronos_pipeline)\n",
    "                results['chronos'].append({\n",
    "                    'date': target_date,\n",
    "                    'origin': origin,\n",
    "                    'horizon': horizon,\n",
    "                    'model': 'Chronos_Tiny',\n",
    "                    'q0.1': pred_chronos['q0.1'],\n",
    "                    'q0.5': pred_chronos['q0.5'],\n",
    "                    'q0.9': pred_chronos['q0.9'],\n",
    "                    'actual': actual\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    for model_name in results:\n",
    "        results[model_name] = pd.DataFrame(results[model_name])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Rolling Forecasts\n",
    "\n",
    "**Warning:** This cell will take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rolling forecast generation...\n",
      "Total iterations: 48\n",
      "\n",
      "This will take approximately 4-5 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 59.60it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1509.83it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1824.40it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1691.25it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 880.23it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1402.31it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1099.42it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 938.74it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:00<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1236.16it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1194.28it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1668.38it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 642.12it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 848.53it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 574.25it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 934.77it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 689.40it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1096.55it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1172.58it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1686.49it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1109.60it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 904.92it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 598.76it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 896.79it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1289.36it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 642.81it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 508.96it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1015.32it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1702.23it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1588.75it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1182.49it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1272.54it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:00<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1232.17it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 739.34it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1325.63it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1258.79it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 663.87it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1235.44it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1943.61it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1447.31it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1248.68it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 553.27it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1020.02it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1515.83it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1583.95it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1466.03it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "\n",
      "Predicting time series: 100%|██████████| 1/1 [00:00<00:00, 1460.92it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing: 100%|██████████| [00:01<00:00]\n",
      "Rolling forecasts: 100%|██████████| 48/48 [06:35<00:00,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Rolling forecasts complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting rolling forecast generation...\")\n",
    "print(f\"Total iterations: {len(ORIGINS) * len(HORIZONS)}\")\n",
    "print(\"\\nThis will take approximately 4-5 minutes...\\n\")\n",
    "\n",
    "forecast_results = run_rolling_forecasts(\n",
    "    ts=ts,\n",
    "    origins=ORIGINS,\n",
    "    horizons=HORIZONS,\n",
    "    min_train=MIN_TRAIN\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Rolling forecasts complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sarima_fourier: 47 forecasts → /home/mikhailarutyunov/projects/time-series-flu/results/forecasts/sarima_fourier.parquet\n",
      "Saved lightgbm: 47 forecasts → /home/mikhailarutyunov/projects/time-series-flu/results/forecasts/lightgbm.parquet\n",
      "Saved tabpfn: 47 forecasts → /home/mikhailarutyunov/projects/time-series-flu/results/forecasts/tabpfn.parquet\n",
      "Saved chronos: 47 forecasts → /home/mikhailarutyunov/projects/time-series-flu/results/forecasts/chronos.parquet\n",
      "\n",
      "✅ All forecast results saved!\n"
     ]
    }
   ],
   "source": [
    "# Save each model's forecasts as parquet\n",
    "for model_name, df in forecast_results.items():\n",
    "    output_path = results_dir / f\"{model_name}.parquet\"\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"Saved {model_name}: {len(df)} forecasts → {output_path}\")\n",
    "\n",
    "print(\"\\n✅ All forecast results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FORECAST COUNT SUMMARY\n",
      "============================================================\n",
      "Horizon         7   28\n",
      "Model                 \n",
      "chronos         24  23\n",
      "lightgbm        24  23\n",
      "sarima_fourier  24  23\n",
      "tabpfn          24  23\n",
      "\n",
      "Total forecasts per model:\n",
      "Model\n",
      "chronos           47\n",
      "lightgbm          47\n",
      "sarima_fourier    47\n",
      "tabpfn            47\n",
      "Name: Forecasts, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display summary of forecast counts by model and horizon\n",
    "summary = []\n",
    "for model_name, df in forecast_results.items():\n",
    "    for horizon in HORIZONS:\n",
    "        count = len(df[df['horizon'] == horizon])\n",
    "        summary.append({\n",
    "            'Model': model_name,\n",
    "            'Horizon': horizon,\n",
    "            'Forecasts': count\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_pivot = summary_df.pivot(index='Model', columns='Horizon', values='Forecasts')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FORECAST COUNT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_pivot)\n",
    "print(\"\\nTotal forecasts per model:\")\n",
    "print(summary_df.groupby('Model')['Forecasts'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Summary\n",
    "\n",
    "**Expected outcomes:**\n",
    "- 4 parquet files in `results/forecasts/` (one per model)\n",
    "- Each file contains forecasts for all origins × horizons\n",
    "- Columns: date, origin, horizon, model, q0.1, q0.5, q0.9, actual\n",
    "- Total runtime: < 5 minutes\n",
    "- No warnings about data leakage or CUDA\n",
    "\n",
    "**Next:** Proceed to `03_evaluation.ipynb` for metrics and statistical tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
